{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2993713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load your cleaned dataset (without 'date' column)\n",
    "df = pd.read_csv(\"data.csv\")  # Replace with your CSV filename\n",
    "\n",
    "# Features and target\n",
    "X = df[['temperature', 'humidity']].values\n",
    "y = df['label'].values  # Make sure you have a column 'label' as 0/1 for anomaly\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into train, val, test sets (70% train, 15% val, 15% test)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a28d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "44/44 [==============================] - 1s 4ms/step - loss: 0.6161 - accuracy: 0.8281 - val_loss: 0.5786 - val_accuracy: 0.8421\n",
      "Epoch 2/30\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.8080 - val_loss: 0.5330 - val_accuracy: 0.8289\n",
      "Epoch 3/30\n",
      "44/44 [==============================] - 0s 989us/step - loss: 0.5271 - accuracy: 0.7994 - val_loss: 0.4934 - val_accuracy: 0.8158\n",
      "Epoch 4/30\n",
      "44/44 [==============================] - 0s 976us/step - loss: 0.4985 - accuracy: 0.7937 - val_loss: 0.4650 - val_accuracy: 0.8158\n",
      "Epoch 5/30\n",
      "44/44 [==============================] - 0s 971us/step - loss: 0.4817 - accuracy: 0.7937 - val_loss: 0.4488 - val_accuracy: 0.8158\n",
      "Epoch 6/30\n",
      "44/44 [==============================] - 0s 974us/step - loss: 0.4713 - accuracy: 0.7937 - val_loss: 0.4405 - val_accuracy: 0.8158\n",
      "Epoch 7/30\n",
      "44/44 [==============================] - 0s 970us/step - loss: 0.4639 - accuracy: 0.7937 - val_loss: 0.4352 - val_accuracy: 0.8158\n",
      "Epoch 8/30\n",
      "44/44 [==============================] - 0s 968us/step - loss: 0.4583 - accuracy: 0.7994 - val_loss: 0.4316 - val_accuracy: 0.8289\n",
      "Epoch 9/30\n",
      "44/44 [==============================] - 0s 991us/step - loss: 0.4533 - accuracy: 0.8080 - val_loss: 0.4264 - val_accuracy: 0.8289\n",
      "Epoch 10/30\n",
      "44/44 [==============================] - 0s 953us/step - loss: 0.4479 - accuracy: 0.8109 - val_loss: 0.4220 - val_accuracy: 0.8421\n",
      "Epoch 11/30\n",
      "44/44 [==============================] - 0s 976us/step - loss: 0.4429 - accuracy: 0.8109 - val_loss: 0.4190 - val_accuracy: 0.8421\n",
      "Epoch 12/30\n",
      "44/44 [==============================] - 0s 979us/step - loss: 0.4388 - accuracy: 0.8166 - val_loss: 0.4170 - val_accuracy: 0.8421\n",
      "Epoch 13/30\n",
      "44/44 [==============================] - 0s 954us/step - loss: 0.4333 - accuracy: 0.8252 - val_loss: 0.4129 - val_accuracy: 0.8421\n",
      "Epoch 14/30\n",
      "44/44 [==============================] - 0s 959us/step - loss: 0.4285 - accuracy: 0.8338 - val_loss: 0.4090 - val_accuracy: 0.8421\n",
      "Epoch 15/30\n",
      "44/44 [==============================] - 0s 994us/step - loss: 0.4243 - accuracy: 0.8338 - val_loss: 0.4059 - val_accuracy: 0.8421\n",
      "Epoch 16/30\n",
      "44/44 [==============================] - 0s 996us/step - loss: 0.4196 - accuracy: 0.8367 - val_loss: 0.4042 - val_accuracy: 0.8421\n",
      "Epoch 17/30\n",
      "44/44 [==============================] - 0s 949us/step - loss: 0.4153 - accuracy: 0.8395 - val_loss: 0.4005 - val_accuracy: 0.8421\n",
      "Epoch 18/30\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8367 - val_loss: 0.3970 - val_accuracy: 0.8421\n",
      "Epoch 19/30\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8395 - val_loss: 0.3943 - val_accuracy: 0.8421\n",
      "Epoch 20/30\n",
      "44/44 [==============================] - 0s 998us/step - loss: 0.4040 - accuracy: 0.8395 - val_loss: 0.3912 - val_accuracy: 0.8421\n",
      "Epoch 21/30\n",
      "44/44 [==============================] - 0s 974us/step - loss: 0.3995 - accuracy: 0.8395 - val_loss: 0.3892 - val_accuracy: 0.8421\n",
      "Epoch 22/30\n",
      "44/44 [==============================] - 0s 981us/step - loss: 0.3954 - accuracy: 0.8424 - val_loss: 0.3864 - val_accuracy: 0.8421\n",
      "Epoch 23/30\n",
      "44/44 [==============================] - 0s 994us/step - loss: 0.3923 - accuracy: 0.8424 - val_loss: 0.3839 - val_accuracy: 0.8421\n",
      "Epoch 24/30\n",
      "44/44 [==============================] - 0s 963us/step - loss: 0.3882 - accuracy: 0.8453 - val_loss: 0.3814 - val_accuracy: 0.8421\n",
      "Epoch 25/30\n",
      "44/44 [==============================] - 0s 952us/step - loss: 0.3845 - accuracy: 0.8510 - val_loss: 0.3784 - val_accuracy: 0.8421\n",
      "Epoch 26/30\n",
      "44/44 [==============================] - 0s 981us/step - loss: 0.3805 - accuracy: 0.8481 - val_loss: 0.3743 - val_accuracy: 0.8421\n",
      "Epoch 27/30\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8539 - val_loss: 0.3709 - val_accuracy: 0.8421\n",
      "Epoch 28/30\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8596 - val_loss: 0.3682 - val_accuracy: 0.8421\n",
      "Epoch 29/30\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8596 - val_loss: 0.3649 - val_accuracy: 0.8421\n",
      "Epoch 30/30\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8596 - val_loss: 0.3621 - val_accuracy: 0.8421\n"
     ]
    }
   ],
   "source": [
    "# Build a small model compatible with TinyML (for Arduino Uno, <32KB flash)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(8, activation='relu', input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=8,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5952a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8421\n",
      "\n",
      "âœ… Validation Accuracy: 84.21%\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8800\n",
      "âœ… Test Accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"\\nâœ… Validation Accuracy: {val_acc * 100:.2f}%\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"âœ… Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681a483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"base_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16f1154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpilr0dwyy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpilr0dwyy/assets\n",
      "2025-06-11 22:25:48.250659: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-06-11 22:25:48.250675: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-06-11 22:25:48.251010: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpilr0dwyy\n",
      "2025-06-11 22:25:48.251777: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-06-11 22:25:48.251784: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpilr0dwyy\n",
      "2025-06-11 22:25:48.253624: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2025-06-11 22:25:48.254637: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-06-11 22:25:48.295209: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpilr0dwyy\n",
      "2025-06-11 22:25:48.307017: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 56008 microseconds.\n",
      "2025-06-11 22:25:48.317280: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Optimize for Microcontrollers\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save modelP\n",
    "with open(\"anomaly_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddd533a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TFLite Model Test Accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"anomaly_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input/output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Run inference on test data\n",
    "y_pred = []\n",
    "for sample in X_test:  # Make sure X_test is scaled\n",
    "    input_data = np.array([sample], dtype=np.float32)  # Batch of 1\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])[0][0]\n",
    "    y_pred.append(1 if output > 0.5 else 0)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"âœ… TFLite Model Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "122751bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ H5 Model Size: 32.45 KB\n",
      "ðŸ“¦ TFLite Model Size: 2.27 KB\n",
      "ðŸ“¦ Quant Model Size: 2.87 KB\n",
      "âœ… Quantized model is suitable for Arduino Uno (size < 32KB)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 0, name: serving_default_dense_input:0 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Run everything\u001b[39;00m\n\u001b[1;32m     61\u001b[0m quant_path_used \u001b[38;5;241m=\u001b[39m print_model_sizes()\n\u001b[0;32m---> 62\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_path_used\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 42\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(tflite_model_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m*\u001b[39minput_shape)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Warm-up\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_details\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Run inference multiple times\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/IITR/Working/dep/venv/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:720\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    705\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 0, name: serving_default_dense_input:0 "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "# Paths\n",
    "h5_path = \"base_model.h5\"\n",
    "tflite_path = \"anomaly_model.tflite\"\n",
    "quant_path = \"quant.tflite\"\n",
    "\n",
    "# Get and print model sizes\n",
    "def print_model_sizes():\n",
    "    h5_size_kb = os.path.getsize(h5_path) / 1024\n",
    "    tflite_size_kb = os.path.getsize(tflite_path) / 1024\n",
    "    quant_size_kb = os.path.getsize(quant_path) / 1024\n",
    "\n",
    "    print(f\"\\nðŸ“¦ H5 Model Size: {h5_size_kb:.2f} KB\")\n",
    "    print(f\"ðŸ“¦ TFLite Model Size: {tflite_size_kb:.2f} KB\")\n",
    "    print(f\"ðŸ“¦ Quant Model Size: {quant_size_kb:.2f} KB\")\n",
    "\n",
    "    if quant_size_kb < 32:\n",
    "        print(\"âœ… Quantized model is suitable for Arduino Uno (size < 32KB)\")\n",
    "    else:\n",
    "        print(\"âŒ Quantized model is NOT suitable for Arduino Uno (size >= 32KB)\")\n",
    "    return quant_path\n",
    "\n",
    "# Load interpreter & estimate runtime and memory\n",
    "def evaluate_model(tflite_model_path):\n",
    "    interpreter = Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_shape = input_details[0]['shape']\n",
    "\n",
    "    # Create dummy input for test\n",
    "    input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "\n",
    "    # Warm-up\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Run inference multiple times\n",
    "    times = []\n",
    "    for _ in range(100):\n",
    "        start = time.time()\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "\n",
    "    avg_time_ms = np.mean(times) * 1000\n",
    "    max_mem_kb = interpreter._get_tensor_details()[-1]['tensor'].nbytes / 1024\n",
    "\n",
    "    print(f\"\\nðŸ§  Estimated Peak Memory Use (RAM): ~{max_mem_kb:.2f} KB (for output tensor only)\")\n",
    "    print(f\"âš¡ Avg Inference Time (on this system): {avg_time_ms:.2f} ms\")\n",
    "\n",
    "# Run everything\n",
    "quant_path_used = print_model_sizes()\n",
    "evaluate_model(quant_path_used)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
