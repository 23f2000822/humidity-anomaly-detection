{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2993713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# === Step 1: Load Original Dataset ===\n",
    "df = pd.read_csv(\"anomaly_data.csv\")  # üîÅ Replace with your dataset\n",
    "\n",
    "# === Step 2: Balance the Dataset via Upsampling ===\n",
    "df_majority = df[df['label'] == 1]  # anomaly\n",
    "df_minority = df[df['label'] == 0]  # normal\n",
    "\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "# === Step 3: Feature Scaling ===\n",
    "X = df_balanced[['temperature', 'humidity']].values\n",
    "y = df_balanced['label'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197aadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 4: Split the Data ===\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, random_state=42)\n",
    "# ‚Üí This gives approx: 70% train, 15% val, 15% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bbbc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 0.6998 - accuracy: 0.5293 - val_loss: 0.6907 - val_accuracy: 0.7020\n",
      "Epoch 2/30\n",
      "88/88 [==============================] - 0s 780us/step - loss: 0.6845 - accuracy: 0.4964 - val_loss: 0.6791 - val_accuracy: 0.4503\n",
      "Epoch 3/30\n",
      "88/88 [==============================] - 0s 837us/step - loss: 0.6723 - accuracy: 0.5608 - val_loss: 0.6716 - val_accuracy: 0.4503\n",
      "Epoch 4/30\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.5179 - val_loss: 0.6649 - val_accuracy: 0.4503\n",
      "Epoch 5/30\n",
      "88/88 [==============================] - 0s 814us/step - loss: 0.6544 - accuracy: 0.5207 - val_loss: 0.6567 - val_accuracy: 0.4503\n",
      "Epoch 6/30\n",
      "88/88 [==============================] - 0s 818us/step - loss: 0.6458 - accuracy: 0.5851 - val_loss: 0.6472 - val_accuracy: 0.4503\n",
      "Epoch 7/30\n",
      "88/88 [==============================] - 0s 759us/step - loss: 0.6342 - accuracy: 0.5966 - val_loss: 0.6354 - val_accuracy: 0.5828\n",
      "Epoch 8/30\n",
      "88/88 [==============================] - 0s 773us/step - loss: 0.6196 - accuracy: 0.7668 - val_loss: 0.6201 - val_accuracy: 0.8675\n",
      "Epoch 9/30\n",
      "88/88 [==============================] - 0s 759us/step - loss: 0.6036 - accuracy: 0.8655 - val_loss: 0.6034 - val_accuracy: 0.9007\n",
      "Epoch 10/30\n",
      "88/88 [==============================] - 0s 767us/step - loss: 0.5862 - accuracy: 0.9027 - val_loss: 0.5887 - val_accuracy: 0.9073\n",
      "Epoch 11/30\n",
      "88/88 [==============================] - 0s 747us/step - loss: 0.5681 - accuracy: 0.8984 - val_loss: 0.5705 - val_accuracy: 0.9272\n",
      "Epoch 12/30\n",
      "88/88 [==============================] - 0s 749us/step - loss: 0.5491 - accuracy: 0.9471 - val_loss: 0.5545 - val_accuracy: 0.9073\n",
      "Epoch 13/30\n",
      "88/88 [==============================] - 0s 752us/step - loss: 0.5288 - accuracy: 0.9471 - val_loss: 0.5343 - val_accuracy: 0.9272\n",
      "Epoch 14/30\n",
      "88/88 [==============================] - 0s 747us/step - loss: 0.5083 - accuracy: 0.9499 - val_loss: 0.5104 - val_accuracy: 0.9470\n",
      "Epoch 15/30\n",
      "88/88 [==============================] - 0s 735us/step - loss: 0.4857 - accuracy: 0.9571 - val_loss: 0.4887 - val_accuracy: 0.9470\n",
      "Epoch 16/30\n",
      "88/88 [==============================] - 0s 742us/step - loss: 0.4625 - accuracy: 0.9642 - val_loss: 0.4661 - val_accuracy: 0.9801\n",
      "Epoch 17/30\n",
      "88/88 [==============================] - 0s 801us/step - loss: 0.4391 - accuracy: 0.9714 - val_loss: 0.4415 - val_accuracy: 0.9735\n",
      "Epoch 18/30\n",
      "88/88 [==============================] - 0s 809us/step - loss: 0.4155 - accuracy: 0.9700 - val_loss: 0.4208 - val_accuracy: 0.9603\n",
      "Epoch 19/30\n",
      "88/88 [==============================] - 0s 730us/step - loss: 0.3917 - accuracy: 0.9742 - val_loss: 0.3958 - val_accuracy: 0.9801\n",
      "Epoch 20/30\n",
      "88/88 [==============================] - 0s 731us/step - loss: 0.3682 - accuracy: 0.9771 - val_loss: 0.3706 - val_accuracy: 0.9801\n",
      "Epoch 21/30\n",
      "88/88 [==============================] - 0s 736us/step - loss: 0.3447 - accuracy: 0.9771 - val_loss: 0.3504 - val_accuracy: 0.9868\n",
      "Epoch 22/30\n",
      "88/88 [==============================] - 0s 723us/step - loss: 0.3232 - accuracy: 0.9785 - val_loss: 0.3234 - val_accuracy: 0.9868\n",
      "Epoch 23/30\n",
      "88/88 [==============================] - 0s 724us/step - loss: 0.3011 - accuracy: 0.9814 - val_loss: 0.3037 - val_accuracy: 0.9868\n",
      "Epoch 24/30\n",
      "88/88 [==============================] - 0s 727us/step - loss: 0.2805 - accuracy: 0.9828 - val_loss: 0.2814 - val_accuracy: 0.9868\n",
      "Epoch 25/30\n",
      "88/88 [==============================] - 0s 717us/step - loss: 0.2616 - accuracy: 0.9814 - val_loss: 0.2617 - val_accuracy: 0.9868\n",
      "Epoch 26/30\n",
      "88/88 [==============================] - 0s 734us/step - loss: 0.2422 - accuracy: 0.9871 - val_loss: 0.2435 - val_accuracy: 0.9868\n",
      "Epoch 27/30\n",
      "88/88 [==============================] - 0s 745us/step - loss: 0.2257 - accuracy: 0.9800 - val_loss: 0.2319 - val_accuracy: 0.9868\n",
      "Epoch 28/30\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9871 - val_loss: 0.2136 - val_accuracy: 0.9868\n",
      "Epoch 29/30\n",
      "88/88 [==============================] - 0s 773us/step - loss: 0.1980 - accuracy: 0.9814 - val_loss: 0.2004 - val_accuracy: 0.9868\n",
      "Epoch 30/30\n",
      "88/88 [==============================] - 0s 796us/step - loss: 0.1844 - accuracy: 0.9843 - val_loss: 0.1881 - val_accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x157aaae60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Step 5: Build Model ===\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# === Step 6: Train Model ===\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=30,\n",
    "          batch_size=8,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a28d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 676us/step\n",
      "‚úÖ Test Accuracy: 0.97\n",
      "üéØ F1 Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# === Step 7: Evaluate Model ===\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Test Accuracy: {acc:.2f}\")\n",
    "print(f\"üéØ F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5952a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 973us/step - loss: 0.1881 - accuracy: 0.9868\n",
      "5/5 [==============================] - 0s 881us/step - loss: 0.1939 - accuracy: 0.9733\n",
      "\n",
      "‚úÖ Validation Accuracy: 98.68%\n",
      "‚úÖ Test Accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "# === Step 4: Evaluate ===\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\n‚úÖ Validation Accuracy: {val_acc*100:.2f}%\")\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "681a483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oscarpatrikminj/Documents/IITR/Working/dep/venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"copy.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15aab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(\"copy.h5\")\n",
    "# Load the model\n",
    "\n",
    "# Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78150568",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd73a525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n",
      "\n",
      "üîç Model Output (Anomaly Probability): 0.5843\n",
      "‚ö†Ô∏è Anomaly Detected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Load the trained .h5 model ===\n",
    "model = tf.keras.models.load_model(\"copy.h5\")\n",
    "\n",
    "# === Use the scaler min and max from training ===\n",
    "temp_min = 5.13\n",
    "temp_max = 44.99\n",
    "hum_min  = 5.2\n",
    "hum_max  = 99.74\n",
    "\n",
    "# === Take manual input ===\n",
    "temperature = float(input(\"üå°Ô∏è Enter temperature (¬∞C): \"))\n",
    "humidity = float(input(\"üíß Enter humidity (%): \"))\n",
    "\n",
    "# === Normalize using same MinMaxScaler logic ===\n",
    "temp_scaled = (temperature - temp_min) / (temp_max - temp_min)\n",
    "hum_scaled = (humidity - hum_min) / (hum_max - hum_min)\n",
    "\n",
    "# Ensure input is in correct shape\n",
    "input_data = np.array([[temp_scaled, hum_scaled]])\n",
    "\n",
    "# === Predict ===\n",
    "output = model.predict(input_data)\n",
    "\n",
    "# === Display Result ===\n",
    "prob = output[0][0]\n",
    "print(f\"\\nüîç Model Output (Anomaly Probability): {prob:.4f}\")\n",
    "if prob > 0.5:\n",
    "    print(\"‚ö†Ô∏è Anomaly Detected\")\n",
    "else:\n",
    "    print(\"‚úÖ Normal Condition\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2280c3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpexwl3in3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpexwl3in3/assets\n",
      "2025-06-13 20:34:06.129876: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-06-13 20:34:06.130082: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-06-13 20:34:06.130999: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpexwl3in3\n",
      "2025-06-13 20:34:06.131752: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-06-13 20:34:06.131759: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpexwl3in3\n",
      "2025-06-13 20:34:06.134074: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2025-06-13 20:34:06.135212: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-06-13 20:34:06.179851: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpexwl3in3\n",
      "2025-06-13 20:34:06.191483: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 60486 microseconds.\n",
      "2025-06-13 20:34:06.220752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(\"copy.h5\")\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open(\"copy.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ba895f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpm0l0syl6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpm0l0syl6/assets\n",
      "2025-06-13 20:34:43.458368: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-06-13 20:34:43.458384: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-06-13 20:34:43.458584: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpm0l0syl6\n",
      "2025-06-13 20:34:43.459342: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-06-13 20:34:43.459350: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpm0l0syl6\n",
      "2025-06-13 20:34:43.462027: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-06-13 20:34:43.502726: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/bs/x0lj933d1hv0py0d4w2ypdp40000gn/T/tmpm0l0syl6\n",
      "2025-06-13 20:34:43.514449: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 55868 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quant_tflite_model = converter.convert()\n",
    "\n",
    "with open(\"quant_copy.tflite\", \"wb\") as f:\n",
    "    f.write(quant_tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "282be729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ H5 Model Size: 32.45 KB\n",
      "üì¶ TFLite Model Size: 2.26 KB\n",
      "üì¶ Quant Model Size: 2.26 KB\n",
      "‚úÖ Quantized model is suitable for Arduino Uno (size < 32KB)\n",
      "\n",
      "üß† Estimated Peak Memory Use (RAM): ~0.00 KB (for output tensor only)\n",
      "‚ö° Avg Inference Time (on this system): 0.01 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "# Paths\n",
    "h5_path = \"copy.h5\"\n",
    "tflite_path = \"copy.tflite\"\n",
    "quant_path = \"quant_copy.tflite\"\n",
    "\n",
    "# Get and print model sizes\n",
    "def print_model_sizes():\n",
    "    h5_size_kb = os.path.getsize(h5_path) / 1024\n",
    "    tflite_size_kb = os.path.getsize(tflite_path) / 1024\n",
    "    quant_size_kb = os.path.getsize(quant_path) / 1024\n",
    "\n",
    "    print(f\"\\nüì¶ H5 Model Size: {h5_size_kb:.2f} KB\")\n",
    "    print(f\"üì¶ TFLite Model Size: {tflite_size_kb:.2f} KB\")\n",
    "    print(f\"üì¶ Quant Model Size: {quant_size_kb:.2f} KB\")\n",
    "\n",
    "    if quant_size_kb < 32:\n",
    "        print(\"‚úÖ Quantized model is suitable for Arduino Uno (size < 32KB)\")\n",
    "    else:\n",
    "        print(\"‚ùå Quantized model is NOT suitable for Arduino Uno (size >= 32KB)\")\n",
    "    return quant_path\n",
    "\n",
    "# Load interpreter & estimate runtime and memory\n",
    "def evaluate_model(tflite_model_path):\n",
    "    interpreter = Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_shape = input_details[0]['shape']\n",
    "\n",
    "    # Create dummy input for test\n",
    "    input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "\n",
    "    # Warm-up\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Run inference multiple times\n",
    "    times = []\n",
    "    for _ in range(100):\n",
    "        start = time.time()\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "\n",
    "    avg_time_ms = np.mean(times) * 1000\n",
    "    # Estimate memory for output tensor only\n",
    "    output_tensor_index = output_details[0]['index']\n",
    "    output_tensor = interpreter.tensor(output_tensor_index)()\n",
    "    max_mem_kb = output_tensor.nbytes / 1024\n",
    "\n",
    "    print(f\"\\nüß† Estimated Peak Memory Use (RAM): ~{max_mem_kb:.2f} KB (for output tensor only)\")\n",
    "    print(f\"‚ö° Avg Inference Time (on this system): {avg_time_ms:.2f} ms\")\n",
    "\n",
    "# Run everything\n",
    "quant_path_used = print_model_sizes()\n",
    "evaluate_model(quant_path_used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i quant_copy.tflite > model_data.cc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
